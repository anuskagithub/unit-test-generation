# ğŸ§ª Unit Test Generator for C/C++ using Local LLM (Ollama)

Automatically generate, refine, and test unit tests for C/C++ applications using a self-hosted LLM like Ollama (e.g., `llama3`, `codellama`). This tool compiles tests, checks build errors, and evaluates code coverage using `gcov`.

---

## ğŸ“ Project Structure

unit-test-gen/
â”œâ”€â”€ input/ # Input C/C++ files and generated test files
â”‚ â”œâ”€â”€ sample.c # Sample C source file
â”‚ â”œâ”€â”€ sample.h # Sample C header file
â”‚ â””â”€â”€ test_sample.c # LLM-generated unit test file
â”œâ”€â”€ prompts/
â”‚ â””â”€â”€ test_prompt.yaml # Strict YAML prompt for LLM
â”œâ”€â”€ main.py # Main script: generate, build, run, and coverage
â”œâ”€â”€ ollama_client.py # Interface to self-hosted LLM (via Ollama CLI)
â””â”€â”€ README.md

---

## ğŸš€ Features

- âœ… Generate unit tests using **Ollama** LLM
- ğŸ› ï¸ Auto-retry test generation if build fails
- ğŸ“Š Measure line coverage using `gcov`
- âš ï¸ Detect and eliminate **duplicate or invalid tests**
- ğŸ“¦ YAML prompt-based control
- ğŸ“¥ Uses `assert.h` (lightweight â€” no frameworks required)

---

## ğŸ› ï¸ Setup Instructions

### 1. Install Dependencies

- GCC and `gcov` (for coverage)
- Python 3.8+
- [Ollama](https://ollama.com) (install + run locally)

### 2. Clone and Set Up

```bash
git clone https://github.com/yourusername/unit-test-gen.git
cd unit-test-gen

```

### 3. Install Python Libraries
```bash
pip install pyyaml

```

## ğŸ§  How It Works
YAML Prompt (prompts/test_prompt.yaml)

```
# instructions.yaml

task: "Generate C/C++ unit tests"

requirements:
  - Use assert-style tests (e.g., assert.h or Google Test if C++)
  - Include all necessary headers for the test to compile
  - Avoid test duplication
  - Ensure all functions are tested at least once
  - Avoid invalid inputs (e.g., division by 0, NULL pointer dereference)
  - Wrap all test cases inside a proper main() function
  - Use readable variable names and comments

formatting:
  - Use consistent indentation (4 spaces)
  - Avoid unnecessary whitespace
  - Comment each test with what itâ€™s testing

output:
  - Provide only the test code, no explanation
  - Wrap all code in a single `main()` function if assert.h is used
  - Return valid compilable code only

language: "C"
```

## Running the Generator
```
python main.py
```

This does the following:
- Cleans up previous build & coverage files
- Sends sample.c + strict YAML prompt to Ollama
- Generates test_sample.c using LLM
- Builds and retries if build fails
- Runs the tests
- Uses gcov to print coverage metrics

## âš™ï¸ Running the LLM (Ollama)

```
bash

ollama run llama3
```

In ollama_client.py, the model name should match:

```
python
subprocess.run(["ollama", "run", "llama3", prompt_text])
```

llama3 can be changed to:
- codellama
- mistral
- phi
- any local model available in your Ollama setup

## ğŸ§ª Sample Output
```
bash
âœ… All tests passed.
ğŸ“‚ Files in 'input/' after running tests:
 - sample.c
 - sample.gcda
 - sample.gcno
 - sample.h
 - sample.o
 - test_sample.c
 - test_sample.gcda
 - test_sample.gcno
 - test_sample.o
 - test_binary.exe

ğŸ“ˆ Line Coverage: 2/2 lines executed âœ… (100.0%)
```

